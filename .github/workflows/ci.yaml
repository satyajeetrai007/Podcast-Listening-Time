name: CI Pipeline

on: 
  push:
    branches: [ main ]

jobs: 
  ci-flow:
    runs-on: ubuntu-latest
    # Added permissions to allow the bot to push code back to the repo
    permissions:
      contents: write
    env: 
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install DVC and Dependencies
      run: |
        pip install --upgrade pip
        pip install dvc[s3] 
        pip install -r requirements.txt

    - name: Pull Data from S3
      run: |
        dvc pull -r myremote

    - name: Run DVC Pipeline
      run: |
        dvc repro

    - name: Push Data and Metadata
      run: |
        # 1. Upload new data/models to S3
        dvc push -r myremote
        
        # 2. Configure Git to push dvc.lock updates
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        
        # 3. Commit and push dvc.lock (using [skip ci] to avoid loops)
        git add dvc.lock
        # Only commit if there are changes
        git diff --quiet && git diff --staged --quiet || (git commit -m "Build: auto-update dvc.lock [skip ci]" && git push)